---
title: 'Isaac Gym for Unitree G1'
date: 2025-11-06
permalink: /posts/2025/11/issacgym/
tags:
  - reinforcement learning
  - humanoids
  - robotics
---

This blog guides through using Issac Gym for training reinforcement learning policies for humanoid robots using Unitree G1.

<a id="repos"></a>
# Repositories

|Name|Description|Installation|
| Issac Gym | Middleware between physics engine and simulation setup. Simplifies simulation setup | 1. Download the Issac Gym repository from the [website](https://developer.nvidia.com/isaac-gym/download) Although the documentation mentions using Ubuntu 18/20, I will be using Ubuntu 22 here.
2. Unzip the repo and run,
```bash
./create_conda_env_rlgpu.sh
```
|
| rsl_rl | A fast and simple implementation of learning algorithms for robotics | 1. Clone https://github.com/leggedrobotics/rsl_rl
2. cd rsl_rl && git checkout v1.0.2 && pip install -e .
|

You can read more of specific repositories below or [skip](#understand_pkgs).
## Issac Gym
Issac Gym is a deprecated Nvidia python package for reinforcement learning. It uses Nvidia's PhysX physics engine. 

[Documentation](https://docs.robotsfan.com/isaacgym)


Issac Gym serves as middleware between you and the physics engine and simulator. It allows you to run complex simulations using one script. 

Issac Gym also has RL policy implementations. 

We will only be using PhysX physics engine here.

<a id="understand_pkgs"></a>
# Understand our packages

## Nomenclature
- Environment - One exclusive space. Usually, one environment is used with one instance of a robot. Each simulation can have multiple environments
- Actors - Actors are instances of assets (objects) in an environment.
- Domain Randomizations - Randomizing properties of actors for each environment in a simulation
- 


------
